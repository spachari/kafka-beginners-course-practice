Producer usually send data that is text-based, for example with JSON data (our twitter data)
In this case, it is important to apply compression to the producer.

Compression is enabled at the producer level and doesn't require any configuration change in the Brokers or in the Consumers
    "compression.type" can be "none" (default), "gzip","lz4","snappy"

Compression is more effective the bigger the batch of message being sent to kafka! (sending the compressed message to kafka
and replicating it between brokers is so much quicker and less latency)

Compressed messages ahve the following advantages:
    Much smaller producer request size (compression ratio uo to 4x!)
    Faster to transfer data over the network => less latency
    Better throughput (data transferred over the network is small)
    Better disk utilization in kafka (stored messages on disk are smaller)

Disadvantages:
    Producers must commit some CPU cycles to compression.
    Consumers must commit some CPU cycles to decomposition.

Overall:
    Consider testing snappy or lz4 for optimal speed/compression ratio

Message Compression Recommendations
    Find a compression algorithm that gives us the best performance for our specific data. Test all of them!

    Always use compression in production and especially if you have high throughput

    Consider tweaking "linger.ms" and "batch.size" to have bigge batches and therefore more compression and higher throughput

